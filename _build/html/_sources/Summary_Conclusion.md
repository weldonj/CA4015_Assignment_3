## Summary and Learning Outcomes

We are confident that we have managed to create some useful models for the classification of sleep status in any potential unseen subject data that was collected in a similar way to the given subject data. We have identified what cleaning and processing was needed on the given subject data to get it prepared for the classification.

We also used many different models and training methods, with simple models and also combined within ensemble AutoML models. We tested their performance and analysed which ones worked best and why. For each model and method we trained and tested them on binary labels, three labels, and also the full five labels.

We found that with our initial classification model, trained on the raw data, "decision tree" and "random forest" were consistently the best options, with the highest accuracy scores for their predictions. "Linear discriminant analysis" and "Linear regression" had a tendency to simply predict that every datapoint was asleep in the binary model, as it provided a high accuracy. But we knew that this is essentially a false accuracy score. Our confusion matrices showed us that this guessing was happening so we could then discount these models despite their high accuracy.

We knew that these classification models were not really viewing our data as a time-series and that to truly analyse the data we needed to extract time series features, so we did this with tsfresh and added these features to each row. When we trained and tested our models on this data with the extracted and added time-series features, "k nearest neighbour" jumped out into the lead on our accuracy scoring, for binary labels, three labels, and the five labels. 

Just like in Assignment 1, we were left with a lot of room to approach this task in whatever way we wanted. As a result we once more had a great chance to "learn by doing". Again we could imagine being faced with quite a similar task in industry and the knowledge that we picked up would definitely stand to us. We hadn't previously done any kind of time series analysis and also limited actual, practical, classification work. We believe we now have a useful grounding in these and would feel confident in tackling something similar with a different time series data set.

It's clear that the data that may be presented to us in future will not be perfectly ready to train and test models on, so the "messiness" of the data in this assignment and the work involved in simply getting it ready for this phase will also stand to us in the future. It's also clear that there isn't a "one approach fits all" model that will work in any situation on any dataset and so it's important to try various approaches and find which works best.

Overall we believe that there was a lot of value in what we have learned throughout this process and we are looking forward to the forecasting task that's up next in assignment 3.