!apt-get install swig -y
!pip install Cython numpy

# sometimes you have to run the next command twice on colab
# I haven't figured out why
!pip install auto-sklearn

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('/content/drive/My Drive/CA4015/sleep_classify')

import pandas as pd
import numpy as np
# read in our windowed features and matching labels

full_set_features = pd.read_csv('/content/drive/My Drive/CA4015/sleep_classify/raw_windowed_features.csv')
full_set_true_labels = pd.read_csv('/content/drive/My Drive/CA4015/sleep_classify/raw_windowed_labels.csv')

# we do not require id and time step columns for this approach
full_set_features = full_set_features.drop(['Unnamed: 0', 'id'], axis=1)
full_set_true_labels = full_set_true_labels.drop(['0', 'id'], axis=1)


full_set_true_labels["1"].unique()

print("Full Set Features", "\n", full_set_features)
print("\nFull Set Labels", "\n", full_set_true_labels)

label_array = full_set_true_labels.values.ravel()
print(label_array.shape)
label_array

# first we'll create a binary label set, indicating 0 for awake and 1 for asleep

binary_label_array = label_array.copy()
binary_label_array[binary_label_array > 0] = 1
np.unique(binary_label_array)

from sklearn.model_selection import train_test_split

# Splitting our data into training and testing sets

X_train, X_test, y_train, y_test = train_test_split(full_set_features, binary_label_array, test_size=0.25)

from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# Implementing a C-Support Vector Classifier, 

clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))
clf.fit(X_train, y_train)

clf.score(X_test, y_test, sample_weight=None)

from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

clf = DecisionTreeClassifier(random_state=0)  # min_samples_leaf=200

scores = cross_val_score(clf, X_train, y_train, cv=5)
print('The mean score and the 95% confidence interval of the score estimate are given by:')
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

# Training the model in a standard way allows to to view the feature importance
# for this model alone.
clf.fit(X_train,y_train)
importance = (clf.feature_importances_)

# using list comprehension + enumerate() 
# index of matching element 
res = [idx for idx, val in enumerate(importance) if val > 0] 
res_feats = [full_set_features.columns[i] for i in res]
  
# print result 
print("\nThe list of features with importance: ") 

print(res_feats)
print("\nimportance\n", importance)

predictions = clf.predict(X_test)
print("\nTest set accuracy:\n", accuracy_score(y_test, predictions), "\n")
print("Confusion Matrix\n", confusion_matrix(y_test, predictions), "\n")

!pip install graphviz
!pip install imageio
import graphviz
import pydotplus
import io
from scipy import misc
import imageio
import matplotlib.pyplot as plt


def show_tree(tree, path):
    f = io.StringIO()
    export_graphviz(tree, out_file=f)
    pydotplus.graph_from_dot_data(f.getvalue()).write_png(path)
    img = imageio.imread(path)
    plt.rcParams["figure.figsize"] = (30,20)
    plt.imshow(img)


show_tree(clf, "binary_dec_tree.png")

from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC

def algorithm_comparison(X_train, y_train, X_test, y_test, n_splits=10):
    models = []
    models.append(("LOGISTIC REGRESSION", LogisticRegression()))
    models.append(("LINEAR DISCRIMINANT AANALYSIS", LinearDiscriminantAnalysis()))
    models.append(("K NEAREST NEIGHBOURS", KNeighborsClassifier()))
    models.append(("NAIVE BAYES", GaussianNB()))
    models.append(("DECISION TREE", DecisionTreeClassifier()))
    models.append(("RANDOM FOREST", RandomForestClassifier()))
    models.append(("SUPPORT VECTOR MACHINE", SVC()))
    models.append(("ADABOOST CLASSIFIER", AdaBoostClassifier()))

    results = []
    names = []

    for name, model in models:
      kfold = model_selection.KFold(n_splits=n_splits)
      cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring="accuracy")
      results.append(cv_results)
      names.append(name)
      print("Model  Mean Accuracy  95% conf interval")
      msg = "{}: {} {}\n".format(name, cv_results.mean(), cv_results.std() * 2)
      print(msg)

      model.fit(X_train, y_train)
      predictions = model.predict(X_test)
      print("Test set accuracy:\n", accuracy_score(y_test, predictions), "\n")
      print("Confusion Matrix\n", confusion_matrix(y_test, predictions), "\n")
      print("Classification report\n" ,classification_report(y_test, predictions), "\n")

    return names, results


names, results = algorithm_comparison(X_train, y_train, X_test, y_test)

import matplotlib.pyplot as plt

def plot_algo_comparison(names, results, title="Algorithm Comparison"):
    fig = plt.figure(figsize=(20,10))
    fig.suptitle(title)
    ax = fig.add_subplot(111)
    plt.boxplot(results)
    ax.set_xticklabels(names)
    plt.show()

plot_algo_comparison(names, results, title="Algorithm Comparison on Binary Label Data")

try:
    import autosklearn.classification
except:
    os.kill(os.getpid(), 9)
import sklearn

# configure auto-sklearn
automl = autosklearn.classification.AutoSklearnClassifier(
          time_left_for_this_task=120, # run auto-sklearn for at most 2min
          per_run_time_limit=30, # spend at most 30 sec for each model training
          )

# train model(s)
automl.fit(X_train, y_train)

# evaluate
y_hat = automl.predict(X_test)
test_acc = sklearn.metrics.accuracy_score(y_test, y_hat)
print("Test Accuracy score {0}".format(test_acc))

# automatic nested cross-validation for random forest on a classification dataset
from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

def nested_cross_val(X_train, y_train, model=KNeighborsClassifier()):

    # configure the cross-validation procedure
    cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)

    # define search space
    pgrid = {"n_neighbors": [5, 10, 30, 70, 100],
              "weights": ["uniform", "distance"],
              "algorithm": ["auto", "ball_tree", "kd_tree", "brute"],
              "leaf_size": [15, 30, 60, 90],
              "p": [1, 2, 4],
              }

    # define search
    search = GridSearchCV(model, pgrid, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)
    # configure the cross-validation procedure
    cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)
    # execute the nested cross-validation
    scores = cross_val_score(search, X_train, y_train, scoring='accuracy', cv=cv_outer, n_jobs=-1)
    # report performance
    print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))

#nested_cross_val(X_train, y_train)

three_label_array = label_array.copy()
three_label_array[(three_label_array == 1) | (three_label_array == 2) | (three_label_array == 3)] = 1
three_label_array[three_label_array == 5] = 2

np.unique(three_label_array)

from sklearn.model_selection import train_test_split

# Splitting our data into training and testing.

X_train, X_test, y_train, y_test = train_test_split(full_set_features, three_label_array, test_size=0.25)

from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier(random_state=0)

scores = cross_val_score(clf, X_train, y_train, cv=5)
print('The mean score and the 95% confidence interval of the score estimate are given by:')
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

# Training the model in a standard way allows to to view the feature importance
# for this model alone.
clf.fit(X_train,y_train)
importance = (clf.feature_importances_)

# using list comprehension + enumerate() 
# index of matching element 
res = [idx for idx, val in enumerate(importance) if val > 0] 
res_feats = [full_set_features.columns[i] for i in res]
  
# print result 
print("\nThe list of features with importance: ") 

print(res_feats)
print("importance\n", importance)

#nested_cross_val(X_train, y_train)

names, results = algorithm_comparison(X_train, y_train, X_test, y_test)

plot_algo_comparison(names, results, title="Algorithm Comparison on Wake / NREM / REM Label Data")

import autosklearn.classification
import sklearn
# configure auto-sklearn
automl = autosklearn.classification.AutoSklearnClassifier(
          time_left_for_this_task=120, # run auto-sklearn for at most 2min
          per_run_time_limit=30, # spend at most 30 sec for each model training
          )

# train model(s)
automl.fit(X_train, y_train)

# evaluate
y_hat = automl.predict(X_test)
test_acc = sklearn.metrics.accuracy_score(y_test, y_hat)
print("Test Accuracy score {0}".format(test_acc))

np.unique(label_array)

from sklearn.model_selection import train_test_split

# Splitting our data into training and testing.
# Please don't ever train on your test data, that's a big no no!
X_train, X_test, y_train, y_test = train_test_split(full_set_features, label_array, test_size=0.25)

from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier(random_state=0)

scores = cross_val_score(clf, X_train, y_train, cv=5)
print('The mean score and the 95% confidence interval of the score estimate are given by:')
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

# Training the model in a standard way allows to to view the feature importance
# for this model alone.
clf.fit(X_train,y_train)
importance = (clf.feature_importances_)

# using list comprehension + enumerate() 
# index of matching element 
res = [idx for idx, val in enumerate(importance) if val > 0] 
res_feats = [full_set_features.columns[i] for i in res]
  
# print result 
print("\nThe list of features with importance: ") 

print(res_feats)
print("importance\n", importance)

#nested_vs_non_plot(X_train, y_train, title="Non-Nested and Nested Cross Validation on Multi-label Sleep Stage Dataset")

names, results = algorithm_comparison(X_train, y_train, X_test, y_test)

plot_algo_comparison(names, results, title="Algorithm Comparison on Wake/N1/N2/N3/REM Label Data")

import autosklearn.classification
import sklearn
# configure auto-sklearn
automl = autosklearn.classification.AutoSklearnClassifier(
          time_left_for_this_task=120, # run auto-sklearn for at most 2min
          per_run_time_limit=30, # spend at most 30 sec for each model training
          )

# train model(s)
automl.fit(X_train, y_train)

# evaluate
y_hat = automl.predict(X_test)
test_acc = sklearn.metrics.accuracy_score(y_test, y_hat)
print("Test Accuracy score {0}".format(test_acc))

import pandas as pd
import numpy as np

extracted_features = pd.read_csv('/content/drive/My Drive/CA4015/sleep_classify/extracted_features.csv')
extracted_labels = pd.read_csv('/content/drive/My Drive/CA4015/sleep_classify/extracted_features_labels.csv')

extracted_features = extracted_features.rename(columns={'Unnamed: 0': 'id', 'Unnamed: 1': 'time'})

extracted_features.head()

# first we'll create a binary label set, indicating 0 for awake and 1 for asleep

e_binary_label_array = extracted_labels['1'].ravel().copy()
e_binary_label_array[e_binary_label_array > 0] = 1
print(np.unique(e_binary_label_array))
print(e_binary_label_array.shape)

print("Extracted Features", "\n", extracted_features)
print("\nExtracted Labels", "\n", e_binary_label_array)

from sklearn.model_selection import train_test_split

# Splitting our data into training and testing.

X_train, X_test, y_train, y_test = train_test_split(extracted_features, e_binary_label_array, test_size=0.25)

from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier(random_state=0)

scores = cross_val_score(clf, X_train, y_train, cv=5)
print('The mean score and the 95% confidence interval of the score estimate are given by:')
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

# Training the model in a standard way allows to to view the feature importance
# for this model alone.
clf.fit(X_train,y_train)
importance = (clf.feature_importances_)

# using list comprehension + enumerate() 
# index of matching element 
res = [idx for idx, val in enumerate(importance) if val > 0] 
res_feats = [extracted_features.columns[i] for i in res]
  
# print result 
print("\nThe list of features with importance: ") 

print(res_feats)
#print("importance\n", importance)

#nested_cross_val(X_train, y_train)

names, results = algorithm_comparison(X_train, y_train, X_test, y_test)

plot_algo_comparison(names, results, title="Algorithm Comparison on Wake/NREM/REM Label Data With Extracted Features")

import autosklearn.classification
import sklearn
# configure auto-sklearn
automl = autosklearn.classification.AutoSklearnClassifier(
          time_left_for_this_task=120, # run auto-sklearn for at most 2min
          per_run_time_limit=30, # spend at most 30 sec for each model training
          )

# train model(s)
automl.fit(X_train, y_train)

# evaluate
y_hat = automl.predict(X_test)
test_acc = sklearn.metrics.accuracy_score(y_test, y_hat)
print("Test Accuracy score {0}".format(test_acc))

e_three_label_array = extracted_labels['1'].ravel().copy()
e_three_label_array[(e_three_label_array == 1) | (e_three_label_array == 2) | (e_three_label_array == 3)] = 1
e_three_label_array[e_three_label_array == 5] = 2

print(np.unique(three_label_array))
print(three_label_array.shape)

from sklearn.model_selection import train_test_split

# Splitting our data into training and testing.

X_train, X_test, y_train, y_test = train_test_split(extracted_features, e_three_label_array, test_size=0.25)



e_label_array = extracted_labels['1'].ravel()
print(e_label_array.shape)
np.unique(e_label_array)

extracted_features = extracted_features.dropna(axis='columns')
extracted_labels["1"].unique()

print("Extracted Features", "\n", extracted_features)
print("\nExtracted Labels", "\n", extracted_labels)

from sklearn.model_selection import train_test_split

# Splitting our data into training and testing.

X_train, X_test, y_train, y_test = train_test_split(extracted_features, e_label_array, test_size=0.25)

from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier(random_state=0)

scores = cross_val_score(clf, X_train, y_train, cv=5)
print('The mean score and the 95% confidence interval of the score estimate are given by:')
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

# Training the model in a standard way allows to to view the feature importance
# for this model alone.
clf.fit(X_train,y_train)
importance = (clf.feature_importances_)

# using list comprehension + enumerate() 
# index of matching element 
res = [idx for idx, val in enumerate(importance) if val > 0] 
res_feats = [extracted_features.columns[i] for i in res]
  
# print result 
print("\nThe list of features with importance: ") 

print(res_feats)
#print("importance\n", importance)

#nested_cross_val(X_train, y_train)

names, results = algorithm_comparison(X_train, y_train, X_test, y_test)

plot_algo_comparison(names, results, title="Algorithm Comparison on Wake/NREM/REM Label Data With Extracted Features")

import autosklearn.classification
import sklearn
# configure auto-sklearn
automl = autosklearn.classification.AutoSklearnClassifier(
          time_left_for_this_task=120, # run auto-sklearn for at most 2min
          per_run_time_limit=30, # spend at most 30 sec for each model training
          )

# train model(s)
automl.fit(X_train, y_train)

# evaluate
y_hat = automl.predict(X_test)
test_acc = sklearn.metrics.accuracy_score(y_test, y_hat)
print("Test Accuracy score {0}".format(test_acc))

feats = extracted_features.columns[2:]
feats

from scipy import stats

standardised = stats.zscore(extracted_features[feats])

details = extracted_features.columns[:2]
df1_std = pd.DataFrame(standardised, columns = feats)
df1_std = df1_std.dropna(axis='columns')
#df1_std = pd.concat([extracted_features[details], df1_std], axis=1)
df1_std

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# use this function to find variance captured in n PCs
# ideally we'd like 75-90% variance captured in 2 or 3 PCs
# to give an accurate representation of the original data

def ideal_pca(df_std):
    dims = 10 # or use len(df_std.columns)
    pca = PCA(n_components = dims)
    pca.fit(df_std)
    variance = pca.explained_variance_ratio_
    variance = np.insert(variance, 0, 0, axis=0)
    var = np.cumsum(np.round(variance, 3)*100)
    plt.figure(figsize=(12,6))
    plt.ylabel('% Variance Explained')
    plt.xlabel('# of Principal Components')
    plt.title('PCA Analysis')
    plt.ylim(0,100.5)
    plt.xlim(0, dims)
    plt.plot(var)
    
ideal_pca(df1_std)

pca3 = PCA(n_components = 5).fit(df1_std)
pca3d = pca3.transform(df1_std)
pca3d_df = pd.DataFrame(pca3d)

print(pca3.explained_variance_ratio_)
print("\nTotal variance captured:\n")
print(sum(pca3.explained_variance_ratio_))

# the % variance captured by our PCs

pca3d_df

from sklearn.model_selection import train_test_split

# Splitting our data into training and testing.
# Please don't ever train on your test data, that's a big no no!
X_train, X_test, y_train, y_test = train_test_split(pca3d_df, e_label_array, test_size=0.25)

from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier(random_state=0)

scores = cross_val_score(clf, X_train, y_train, cv=5)
print('The mean score and the 95% confidence interval of the score estimate are given by:')
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))

# Training the model in a standard way allows to to view the feature importance
# for this model alone.
clf.fit(X_train,y_train)
importance = (clf.feature_importances_)

# using list comprehension + enumerate() 
# index of matching element 
res = [idx for idx, val in enumerate(importance) if val > 0] 
res_feats = [extracted_features.columns[i] for i in res]
  
# print result 
print("\nThe list of features with importance: ") 

print(res_feats)
print("importance\n", importance)

import autosklearn.classification
import sklearn
# configure auto-sklearn
automl = autosklearn.classification.AutoSklearnClassifier(
          time_left_for_this_task=120, # run auto-sklearn for at most 2min
          per_run_time_limit=30, # spend at most 30 sec for each model training
          )

# train model(s)
automl.fit(X_train, y_train)

# evaluate
y_hat = automl.predict(X_test)
test_acc = sklearn.metrics.accuracy_score(y_test, y_hat)
print("Test Accuracy score {0}".format(test_acc))


